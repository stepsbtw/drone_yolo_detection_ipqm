# Drone YOLO Detection Pipeline

A computer vision pipeline for detecting people in drone footage with optional weapon detection using YOLOv11 and YOLOv8 models.

## ğŸ¯ Features

- **Person Detection**: YOLOv11 for high-performance person detection
- **Distance Estimation**: Estimates distance from camera using drone intrinsic parameters (EVO 2 Dual V2)
- **Weapon Detection**: Optional YOLOv8-based weapon detection on person crops
- **Majority Voting**: Sample-level classification using configurable frame threshold to reduce false positives
- **Comprehensive Metrics**: Per-frame, per-sample, per-class, per-distance, and per-height statistics with RMSE tracking
- **Batch Processing**: Process single images, directories, or entire sample collections
- **Organized Output**: Structured results with separate folders for detections, crops, and weapon analysis
- **Docker Support**: Containerized deployment option

## ğŸ“ Project Structure

```
drone_yolo_detection/
â”œâ”€â”€ src/                     # ğŸ“ Source code
â”‚   â”œâ”€â”€ __init__.py         
â”‚   â”œâ”€â”€ config.py           # âš™ï¸ Configuration settings
â”‚   â”œâ”€â”€ detector.py         # ğŸ§  Main detection logic
â”‚   â”œâ”€â”€ estimation.py       # ğŸ“ Distance estimation logic
â”‚   â”œâ”€â”€ weapon_detector.py  # ğŸ”« Weapon detection logic
â”‚   â””â”€â”€ main.py             # ğŸš€ CLI interface
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ people/
â”‚   â”‚   â””â”€â”€ yolo11n.pt          # ğŸ¤– YOLOv11 model for person detection
â”‚   â””â”€â”€ weapons/
â”‚       â””â”€â”€ yolov8guns.pt       # ğŸ”« YOLOv8 model for weapon detection
â”œâ”€â”€ inputs/
â”‚   â”œâ”€â”€ raw/                # Original video files (.mp4)
â”‚   â”œâ”€â”€ clips/              # Processed video clips
â”‚   â””â”€â”€ samples/            # Frame samples extracted from clips
â”œâ”€â”€ output/                 # ğŸ’¾ Results will be saved here
â”‚   â”œâ”€â”€ detections/         # Images with bounding boxes
â”‚   â”œâ”€â”€ crops/              # Individual person crops
â”‚   â””â”€â”€ weapon_detections/  # Person crops with weapon analysis
â”œâ”€â”€ Dockerfile              # ğŸ³ Docker configuration
â”œâ”€â”€ requirements.txt        # ğŸ“¦ Python dependencies
â”œâ”€â”€ preprocess_videos.py    # ğŸ“¹ Video preprocessing
â””â”€â”€ README.md              # ğŸ“– This documentation
```

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Run the pipeline
python src/main.py

# With Docker
docker build -t people-detector .
docker run -v $(pwd):/workspace people-detector
```

## ğŸ“Š Usage Examples

```bash
# Process all sample directories
python src/main.py --input inputs/samples --output output/batch_results

# Custom confidence thresholds
python src/main.py --confidence 0.6 --weapon-confidence 0.3

# Adjust majority voting (require 3+ frames with weapons to classify sample)
python src/main.py --majority-threshold 3

# Disable weapon detection
python src/main.py --no-weapons

# Full configuration
python src/main.py --model models/people/yolo11n.pt \
                   --weapon-model models/weapons/yolov8guns.pt \
                   --input inputs/samples \
                   --output output/detections \
                   --confidence 0.6 \
                   --weapon-confidence 0.25 \
                   --majority-threshold 2 \
                   --save-crops
```

## ğŸ”§ Configuration

### Command Line Arguments
- `--model`: Path to YOLO person detection model (default: `models/people/yolo11n.pt`)
- `--weapon-model`: Path to YOLOv8 weapon model (default: `models/weapons/yolov8guns.pt`)
- `--input`: Input directory containing image folders (default: `inputs/samples`)
- `--input_with_weapons`: Input directory with weapon samples (optional, for ground truth)
- `--input_without_weapons`: Input directory without weapon samples (optional, for ground truth)
- `--output`: Output directory (default: `output/detections`)
- `--confidence`: Person detection threshold, 0.0-1.0 (default: 0.5)
- `--weapon-confidence`: Weapon detection threshold, 0.0-1.0 (default: 0.2)
- `--sample-majority-threshold`: Frames with weapons needed to classify sample (default: 1)
- `--save-crops`: Save person crops (default: enabled)
- `--no-crops`: Disable saving person crops
- `--no-weapons`: Disable weapon detection

### Configuration File
Edit `src/config.py` to customize defaults:
- Confidence thresholds
- Bounding box colors
- Supported image formats
- Output settings
- Crop padding and minimum size

## ğŸ“ Output Structure

```
output/
â”œâ”€â”€ detections/                    # Images with person bounding boxes
â”‚   â”œâ”€â”€ image1_detected.jpg
â”‚   â””â”€â”€ image2_detected.jpg
â”œâ”€â”€ crops/                         # Individual person crops
â”‚   â”œâ”€â”€ image1_person_01_conf_0.85.jpg
â”‚   â””â”€â”€ image1_person_02_conf_0.92.jpg
â””â”€â”€ weapon_detections/             # Person crops with weapon analysis
    â”œâ”€â”€ image1_person_01_conf_0.85_weapon_check.jpg
    â””â”€â”€ image1_person_02_conf_0.92_weapon_check.jpg
```

## ğŸ“¹ Video Preprocessing

Process raw videos into clips and frame samples using `preprocess_videos.py`:

```bash
# Basic usage
python preprocess_videos.py

# Custom parameters
python preprocess_videos.py -X 15 -Z 1080p -W 60 -C compressed -F 15 -B 1M
```

### Parameters
- `-X, --clip-duration`: Clip duration in seconds (default: 10)
- `-Z, --resolution`: Target resolution - 1080p, 720p, 480p, 360p, 240p (default: 720p)
- `-W, --frame-interval`: Extract 1 frame every W frames (default: 30)
- `-C, --compression`: Quality preset - high_quality, balanced, compressed, very_compressed (default: balanced)
- `-F, --fps`: Target FPS (optional)
- `-B, --max-bitrate`: Maximum bitrate limit, e.g., '2M', '1000k' (optional)

## ğŸ—ï¸ Pipeline Components

### 1. Person Detection (YOLOv11)
- **Model**: YOLOv11n (nano) for fast inference
- **Target**: COCO person class (ID: 0)
- **Output**: Bounding boxes with confidence scores

### 2. Distance Estimation
Uses drone camera intrinsic parameters to estimate distance:
- **Camera**: EVO 2 Dual V2
- **Sensor**: 6.4mm x 4.8mm
- **Focal Length**: 25.6mm (35mm equivalent)
- **Resolution**: 1920x1080 pixels
- **Method**: Calculates distance from person pixel height and camera focal length
- **Assumption**: Average person height of 1.7m
- **Formula**: `distance = (real_height Ã— focal_length) / (pixel_height Ã— pixel_size)`
- **Accuracy**: Typically within 20-30% of actual distance
- **Output**: Distance logs saved to `person_distances.log`

### 3. Crop Extraction
- **Padding**: 10% padding around person bounding boxes
- **Minimum Size**: 32x32 pixels
- **Format**: JPEG files with metadata in filename

### 4. Weapon Detection (YOLOv8)
- **Model**: YOLOv8 custom-trained for weapon detection
- **Input**: Person crops from step 3
- **Majority Voting**: Sample classified as having weapons if â‰¥ threshold frames contain weapons
- **Threshold**: Configurable via `--majority-threshold` (default: 1)
- **Output**: Annotated crops with weapon bounding boxes

## ğŸ“Š Metrics Tracking

The pipeline tracks comprehensive metrics:

- **Frame-Level**: Per-frame confusion matrix (TP, TN, FP, FN)
- **Sample-Level**: Per-sample confusion matrix using majority voting
- **Per-Class**: Metrics segmented by sample class (e.g., 'real', 'falso')
- **Per-Distance**: Metrics segmented by real distance
- **Per-Height**: Metrics segmented by camera height
- **Distance RMSE**: Root Mean Squared Error for distance estimation

Ground truth is determined from filenames: 'real*' = has weapons, 'falso*' = no weapons.

## ğŸ³ Docker

```bash
# Build
docker build -t people-detector .

# Run with default settings
docker run -v $(pwd):/workspace people-detector

# Run with custom parameters
docker run -v $(pwd):/workspace people-detector \
    python src/main.py --confidence 0.7 --output custom_results/
```
